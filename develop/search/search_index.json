{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#lintdb","title":"LintDB","text":"<p>LintDB is a multi-vector database meant for Gen AI. LintDB natively supports late interaction like ColBERT and PLAID.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multi vector support: LintDB stores multiple vectors per document id and calculates the max similarity across vectors to determine relevance. </li> <li>Bit-level Compression: LintDB fully implements PLAID's bit compression, storing 128 dimension embeddings in as low as 16 bytes.  </li> <li>Embedded: LintDB can be embedded directly into your Python application. No need to setup a separate database.  </li> <li>Full Support for PLAID and ColBERT: LintDB is built around PLAID and ColBERT.</li> <li>Filtering: LintDB supports filtering on any field in the schema.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>LintDB relies on OpenBLAS for accerlated matrix multiplication. To smooth the process of installation, we only support conda.</p> <pre><code>conda install lintdb -c deployql -c conda-forge\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>LintDB makes it easy to upload data, even if you have multiple tenants.</p> <p>Below shows creating a database. LintDB defines a schema for a given database that can be used to index embeddings, floats, strings, even dates. Fields can be indexed, stored, or used as a filter. <pre><code>from lintdb.core import (\n  Schema,\n  ColbertField,\n  QuantizerType,\n  Configuration,\n  IndexIVF\n)\n\nschema = Schema(\n  [\n    ColbertField('colbert', DataType.TENSOR, {\n      'dimensions': 128,\n      'quantization': QuantizerType.BINARIZER,\n      \"num_centroids\": 32768,\n      \"num_iterations\": 10,\n    })\n  ]\n)\nconfig = Configuration()\nindex = IndexIVF(index_path, schema, config)\n)\n</code></pre></p> <p>And querying the database. We can query any of the data fields we indexed. <pre><code>from lintdb.core import (\nQuery,\nVectorQueryNode\n)\nfor id, query in zip(data.qids, data.queries):\n  embedding = checkpoint.queryFromText(query)\ne = np.squeeze(embedding.cpu().numpy().astype('float32'))\n\nquery = Query(\n  VectorQueryNode(\n    TensorFieldValue('colbert', e)\n  )\n)\nresults = index.search(0, query, 10)\nprint(results)\n</code></pre></p>"},{"location":"#late-interaction-model-support","title":"Late Interaction Model Support","text":"<p>LintDB aims to support late interaction and more advanced retrieval models. </p> <ul> <li> ColBERTv2 with PLAID</li> <li> XTR</li> </ul>"},{"location":"#roadmap","title":"Roadmap","text":"<p>LintDB aims to be a retrieval platform for Gen AI. We believe that to do this, we must support flexible retrieval and scoring methods while maintaining a high level of performance.</p> <ul> <li>Improving performance and scalability</li> <li>Improved benchmarks</li> <li>Support CITADEL for scalable late interaction</li> <li>Support learnable query adapters in the retrieval pipeline</li> <li>Enhance support for arbitrary retrieval and ranking functions</li> <li>Support learnable ranking functions</li> </ul>"},{"location":"#comparison-with-other-vector-databases","title":"Comparison with other Vector Databases","text":"<p>LintDB is one of two databases that support token level embeddings. The other being Vespa.</p>"},{"location":"#token-level-embeddings","title":"Token Level Embeddings","text":""},{"location":"#vespa","title":"Vespa","text":"<p>Vespa is a robust, mature search engine with many features. However, the learning curve to get started and operate Vespa is high. With embedded LintDB, there's no setup required. <code>conda install lintdb -c deployql</code> and get started.</p>"},{"location":"#embedded","title":"Embedded","text":""},{"location":"#chroma","title":"Chroma","text":"<p>Chroma is an embedded vector database available in Python and Javascript. LintDB currently only supports Python. </p> <p>However, unlike Chroma, LintDB offers multi-tenancy support.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>For detailed documentation on using LintDB, refer to the official documentation</p>"},{"location":"#license","title":"License","text":"<p>LintDB is licensed under the Apache 2.0 License. See the LICENSE file for details.</p>"},{"location":"#we-want-to-offer-a-managed-service","title":"We want to offer a managed service","text":"<p>We need your help! If you'd want a managed LintDB, reach out and let us know. </p> <p>Book time on the founder's calendar: https://calendar.app.google/fsymSzTVT8sip9XX6</p>"},{"location":"development/","title":"Development","text":""},{"location":"development/#lintdb-c-libraries","title":"LintDB C++ Libraries","text":"<p>To develop on LintDB, there are a few dependencies that you need to install. The below instructions are for Ubuntu.</p>"},{"location":"development/#vcpkg","title":"vcpkg","text":"<pre><code>git clone https://github.com/microsoft/vcpkg.git\ncd vcpkg &amp;&amp; ./bootstrap-vcpkg.sh\n</code></pre>"},{"location":"development/#clang","title":"clang","text":"<p>We expect clang as the compiler. This helps align with our expectations of MKL libraries detailed below. <pre><code>wget https://apt.llvm.org/llvm.sh\nchmod +x llvm.sh\nsudo ./llvm.sh all\n</code></pre></p>"},{"location":"development/#miniforge-recommended","title":"miniforge (recommended)","text":"<p>Miniforge is a minimal installer for conda that automatically installs conda-forge packages.</p> <p>We can create an isolated environment for lintdb development. <pre><code>conda create -n lintdb python=3.10\nconda activate lintdb\n</code></pre></p>"},{"location":"development/#recommended-python-libraries","title":"Recommended Python Libraries","text":"<p>There are a few helpful python libraries that are used in profiling and testing LintDB. <pre><code>pip install graph2dot\n</code></pre></p>"},{"location":"development/#python-lintdb","title":"Python LintDB","text":"<p>In addition to the above, developing with the Python LintDB library requires a few more dependencies.</p> <p>LintDB uses nanobind to create Python bindings. It also comes with a helpful CLI tool to create stubs for Python.</p> <pre><code>pip install nanobind\n</code></pre>"},{"location":"development/#creating-python-stubs","title":"creating python stubs","text":"<pre><code>python -m nanobind.stubgen -m lintdb.core -M py.typed -o core.pyi \n</code></pre>"},{"location":"development/#makefile-commands","title":"Makefile commands","text":"<p>The Makefile at the root of the repository has a few commands that can help you get started. CMakePresets.json is used to configure the build system.</p> <pre><code># build a debug target with tests.\nmake build-debug\n\n# build a release target\nmake build-release\n\n# run tests\nmake tests\n\n# run benchmarks\nmake benchmarks\n\n# profile LintDB (note some variables need to change in the Makefile)\nmake callgrind\n</code></pre> <p>You'll notice that each target is statically linked. However, we dynamically depend on finding either MKL or OpenBLAS at runtime.</p>"},{"location":"development/#mkl-vs-openblas","title":"MKL vs OpenBLAS","text":"<p>LintDB currently uses either MKL or OpenBLAS for linear algebra operations. By default, we use MKL on Windows and Ubuntu. On MacOS, we use OpenBLAS. </p> <p>It should be noted that MKL doesn't always play well with OpenMP. We specify linking against intel's version of OpenMP, but at runtime, it's possible we find a different version. This can lead to performance issues.</p> <p>It can be helpful to refer to Intel's threading layer documentation and try <code>INTEL</code> or <code>GNU</code>. Running <code>ldd path/to/liblintdb_lib.so</code> will output what libraries are being linked at runtime to verify if there are issues.</p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#colpali-processing-pdfs","title":"ColPali: Processing PDFs","text":"<p>ColPali is a recent advancement in efficient document retrieval. Instead of using a traditional document processing pipeline to extract data, ColPali takes embeddings of the image of the PDFs. See: ColPali</p>"},{"location":"examples/#install-dependencies","title":"Install Dependencies","text":"<pre><code>conda install -c deployql lintdb\n\n# make sure to update the url depending on your cuda version.\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\npip install transformers tqdm  git+https://github.com/illuin-tech/colpali\n</code></pre>"},{"location":"examples/#login-to-huggingface","title":"Login to Huggingface","text":"<p>ColPali is built on top of PaliGemma, which requires user agreement in the HF model hub. </p> <p>To login to the Huggingface model hub, see here: Huggingface Gated Models Documentation</p>"},{"location":"examples/#define-our-imports","title":"Define our imports","text":"<pre><code>from lintdb.core import (\n    Schema,\n    ColbertField,\n    QuantizerType,\n    Binarizer,\n    Configuration,\n    SearchOptions,\n    DataType,\n    FieldValue,\n    TensorFieldValue,\n    Document,\n    IndexIVF,\n    VectorQueryNode,\n    Query\n)\nimport torch\nimport typer\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom transformers import AutoProcessor\nfrom PIL import Image\nimport numpy as np\n\nfrom colpali_engine.models.paligemma_colbert_architecture import ColPali\nfrom colpali_engine.trainer.retrieval_evaluator import CustomEvaluator\nfrom colpali_engine.utils.colpali_processing_utils import process_images, process_queries\nfrom colpali_engine.utils.image_from_page_utils import load_from_dataset\n</code></pre> <p>We import the necessary libraries to run ColPali, including the <code>lintdb</code> library for indexing and searching, and the <code>colpali_engine</code> library for processing.</p>"},{"location":"examples/#load-the-model","title":"Load the model","text":"<pre><code>model_name = \"vidore/colpali\"\nmodel = ColPali.from_pretrained(\"google/paligemma-3b-mix-448\", torch_dtype=torch.bfloat16, device_map=\"cuda\").eval()\nmodel.load_adapter(model_name)\nprocessor = AutoProcessor.from_pretrained(model_name)\n</code></pre>"},{"location":"examples/#load-sample-data","title":"Load sample data","text":"<pre><code>images = load_from_dataset(\"vidore/docvqa_test_subsampled\")\nqueries = [\"From which university does James V. Fiorca come ?\", \"Who is the japanese prime minister?\"]\n\ndataloader = DataLoader(\n    images,\n    batch_size=4,\n    shuffle=False,\n    collate_fn=lambda x: process_images(processor, x),\n)\nds = []\nfor batch_doc in tqdm(dataloader):\n    with torch.no_grad():\n        batch_doc = {k: v.to(model.device) for k, v in batch_doc.items()}\n        embeddings_doc = model(**batch_doc)\n    ds.extend(list(torch.unbind(embeddings_doc.to(\"cpu\"))))\n</code></pre>"},{"location":"examples/#index-the-data","title":"Index the data","text":"<pre><code># train the index\nnum_embeddings = sum([x.type(torch.FloatTensor).numpy().shape[0] for x in ds])\n\nschema = Schema(\n    [\n        ColbertField('colbert', DataType.TENSOR, {\n            'dimensions': 128,\n            'quantization': QuantizerType.BINARIZER,\n            \"num_centroids\": 717,\n            \"num_iterations\": 10,\n        })\n    ]\n)\nconfig = Configuration()\nindex = IndexIVF('vidore-sample.db', schema, config)\n\n\ntraining_docs = []\nfor emb in ds:\n    emb = np.squeeze(emb.type(torch.FloatTensor).numpy().astype('float32'))\n    doc = Document(0, [TensorFieldValue(\"colbert\", emb)])\n    training_docs.append(doc)\nindex.train(training_docs)\n\n# index the documents.\nfor i, emb in enumerate(ds):\n    emb = np.squeeze(emb.type(torch.FloatTensor).numpy().astype('float32'))\n    doc = Document(i, [TensorFieldValue(\"colbert\", emb)])\n    index.add(0, [doc])\n</code></pre>"},{"location":"examples/#query-the-data","title":"Query the data","text":"<pre><code>for query in qs:\n  root = VectorQueryNode(TensorFieldValue('colbert', query.type(torch.FloatTensor).numpy().astype('float32')))\n  query = Query(root)\n  results = index.search(0, query, 10, {\n      'n_probe': 32,\n      'colbert_field': 'colbert',\n      'k_top_centroids': 2,\n  })\n  for i in range(5):\n    print(results[i].id)\n  print(\"----\")\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<p>To install the package, run the following command:</p> <pre><code>conda install -c deployql lintdb\n</code></pre>"},{"location":"getting-started/#usage","title":"Usage","text":""},{"location":"getting-started/#load-data","title":"Load data","text":"<p>Let's use LoTTE data to create a new database.</p> <pre><code>from datasets import load_dataset\nfrom collections import namedtuple\n\nLoTTeDataset = namedtuple('LoTTeDataset', ['collection', 'queries', 'qids', 'dids'])\n\n# get the LoTTE dataset and queries\ncollection_dataset = load_dataset(\"colbertv2/lotte_passages\", 'lifestyle')\ncollection = [x['text'] for x in collection_dataset[split + '_collection']]\ndids = [x['doc_id'] for x in collection_dataset[split + '_collection']]\n\nqueries_dataset = load_dataset(\"colbertv2/lotte\", dataset)\nqueries = [x['query'] for x in queries_dataset['search_' + split]]\nqids = [x['qid'] for x in queries_dataset['search_' + split]]\n\ndata = LoTTeDataset(collection, queries, qids, dids)\n</code></pre>"},{"location":"getting-started/#load-a-colbert-model","title":"Load a ColBERT model","text":"<p>We can reuse the ColBERT model from the Hugging Face model hub.</p> <pre><code>from colbert.modeling.checkpoint import Checkpoint\nfrom colbert import Searcher\nconfig = ColBERTConfig.load_from_checkpoint(\"colbert-ir/colbertv2.0\")\ncheckpoint = Checkpoint(\"colbert-ir/colbertv2.0\", config)\n</code></pre>"},{"location":"getting-started/#create-a-database","title":"Create a database","text":"<p>LintDB requires a schema to be defined for a database.</p> <p>We can create a simple ColBERT schema as follows:</p> <pre><code>from lintdb.core import (\nSchema,\nColbertField,\nQuantizerType,\nConfiguration,\nIndexIVF\n)\n\nschema = Schema(\n    [\n        ColbertField('colbert', DataType.TENSOR, {\n            'dimensions': 128,\n            'quantization': QuantizerType.BINARIZER,\n            \"num_centroids\": 32768,\n            \"num_iterations\": 10,\n        })\n    ]\n)\nconfig = Configuration()\nindex = IndexIVF(index_path, schema, config)\n</code></pre> <p>Let's look at the schema we just created:</p> <pre><code>ColbertField('colbert',  # field name\n     DataType.TENSOR, # data type\n     {\n        'dimensions': 128,  # number of dimensions\n        'quantization': QuantizerType.BINARIZER, # the type of quantizer to use.\n        \"num_centroids\": 32768, # the number of centroids to use in training.\n        \"num_iterations\": 10, # the number of iterations to use in training.\n    }\n)\n</code></pre> <p>ColBERT stores token embeddings of 128 dimensions. Our Quantizer <code>BINARIZER</code> is directly translated out of the original ColBERT implementation.</p> <p>The number of centroids as defined in ColBERT should be the square root of the total number of embeddings.</p>"},{"location":"getting-started/#training","title":"Training","text":"<p>Before we can index data, we need to train the database to learn what clusters to assign the embeddings to.</p> <pre><code>from lintdb.core import (\nDocument,\nTensorFieldValue\n)\ntraining_docs = []\ntraining_data = random.sample(data.collection, min(20000, len(d.collection)))\nfor b in tqdm(batch(training_data, n=1000)):\n    embeddings = checkpoint.docFromText(b)\n    for emb in embeddings:\n        emb = np.squeeze(emb.cpu().numpy().astype('float32'))\n        doc = Document(0, [TensorFieldValue(\"colbert\", emb)])\n        training_docs.append(doc)\n\n    index.train(training_docs)\n</code></pre> <p>Let's take a closer look at the Document we pass to LintDB: <pre><code>Document(0, # the tenant id. must be an int.\n         [ # a list of field values.\n             TensorFieldValue( # specifies that we're passing in tensors.\n                 \"colbert\",  # the field name\n                 emb # the embedding. must be a 2D numpy array (n, 128) of float32.\n             )\n         ]\n         )\n</code></pre> Each document must match the schema for the database.</p>"},{"location":"getting-started/#indexing","title":"Indexing","text":"<p>Now that we have trained the database, we can index the data.</p> <pre><code> for b in tqdm(batch(list(zip(d.dids, d.collection)),n=1)):\n        ids = [i for i,_ in b]\n        docs = [d for _, d in b]\n\n        embedding = checkpoint.docFromText(docs)\n\n        e = np.squeeze(embedding.cpu().numpy().astype('float32'))\n\n        for i, ee in zip(ids, e):\n            doc = Document(i, [TensorFieldValue(\"colbert\", e)])\n            index.add(0, [doc])\n</code></pre>"},{"location":"getting-started/#searching","title":"Searching","text":"<p>Now that we have indexed the data, we can search the database.</p> <pre><code>from lintdb.core import (\nQuery,\nVectorQueryNode\n)\nfor id, query in zip(data.qids, data.queries):\n    embedding = checkpoint.queryFromText(query)\n    e = np.squeeze(embedding.cpu().numpy().astype('float32'))\n\n    query = Query(\n        VectorQueryNode(\n            TensorFieldValue('colbert', e)\n        )\n    )\n    results = index.search(0, query_doc, 10)\n    print(results)\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>LintDB requires Python 3.10 or later.</p>"},{"location":"installation/#installing-using-conda-recommended","title":"Installing using conda (recommended)","text":"<p>We highly recommend using conda to install LintDB.</p> <pre><code>conda install -c DeployQL lintdb\n</code></pre> <p>If you don't have conda, you can install it from here.</p>"},{"location":"nav/","title":"Nav","text":"<ul> <li>Introduction</li> <li>Getting Started</li> <li>Installation</li> <li>Examples</li> <li>Development</li> <li>Reference</li> </ul>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#lintdb.core","title":"core","text":""},{"location":"reference/#lintdb.core.ColBERTContextData","title":"ColBERTContextData","text":"<pre><code>ColBERTContextData()\n</code></pre> <p>ColBERT context data</p> <p>Default constructor</p>"},{"location":"reference/#lintdb.core.ColBERTContextData.doc_codes","title":"doc_codes  <code>property</code>","text":"<pre><code>doc_codes\n</code></pre> <p>Document codes</p>"},{"location":"reference/#lintdb.core.ColBERTContextData.doc_residuals","title":"doc_residuals  <code>property</code>","text":"<pre><code>doc_residuals\n</code></pre> <p>Document residuals</p>"},{"location":"reference/#lintdb.core.Configuration","title":"Configuration","text":"<pre><code>Configuration()\n</code></pre> <p>Configuration for the index</p> <p>Default constructor</p>"},{"location":"reference/#lintdb.core.Configuration.lintdb_version","title":"lintdb_version  <code>property</code>","text":"<pre><code>lintdb_version\n</code></pre> <p>LintDB version</p>"},{"location":"reference/#lintdb.core.DataType","title":"DataType","text":"<p>               Bases: <code>enum.Enum</code></p>"},{"location":"reference/#lintdb.core.DataType.COLBERT","title":"COLBERT","text":"<pre><code>COLBERT = DataType.COLBERT\n</code></pre> <p>Colbert data type</p>"},{"location":"reference/#lintdb.core.DataType.DATETIME","title":"DATETIME","text":"<pre><code>DATETIME = DataType.DATETIME\n</code></pre> <p>Datetime data type</p>"},{"location":"reference/#lintdb.core.DataType.FLOAT","title":"FLOAT","text":"<pre><code>FLOAT = DataType.FLOAT\n</code></pre> <p>Float data type</p>"},{"location":"reference/#lintdb.core.DataType.INTEGER","title":"INTEGER","text":"<pre><code>INTEGER = DataType.INTEGER\n</code></pre> <p>Integer data type</p>"},{"location":"reference/#lintdb.core.DataType.QUANTIZED_TENSOR","title":"QUANTIZED_TENSOR","text":"<pre><code>QUANTIZED_TENSOR = DataType.QUANTIZED_TENSOR\n</code></pre> <p>Quantized tensor data type</p>"},{"location":"reference/#lintdb.core.DataType.TENSOR","title":"TENSOR","text":"<pre><code>TENSOR = DataType.TENSOR\n</code></pre> <p>Tensor data type</p>"},{"location":"reference/#lintdb.core.DataType.TEXT","title":"TEXT","text":"<pre><code>TEXT = DataType.TEXT\n</code></pre> <p>Text data type</p>"},{"location":"reference/#lintdb.core.DateTime","title":"DateTime","text":"<pre><code>DateTime()\n</code></pre> <p>DateTime type</p> <p>Default constructor</p>"},{"location":"reference/#lintdb.core.DateTime.from_python","title":"from_python","text":"<pre><code>from_python()\n</code></pre> <p>from_python(arg: object, /) -&gt; lintdb.core.DateTime</p> <p>Convert from Python datetime</p>"},{"location":"reference/#lintdb.core.DateTime.to_python","title":"to_python  <code>method descriptor</code>","text":"<pre><code>to_python()\n</code></pre> <p>to_python(self) -&gt; object</p> <p>Convert to Python datetime</p>"},{"location":"reference/#lintdb.core.Document","title":"Document","text":"<pre><code>Document()\n</code></pre> <p>Document for storing multiple fields and a unique ID.</p> <p>Constructor with ID and fields.</p> <p>:param id: Unique ID of the document. :param fields: List of FieldValue objects.</p>"},{"location":"reference/#lintdb.core.Document.fields","title":"fields  <code>property</code>","text":"<pre><code>fields\n</code></pre> <p>List of FieldValue objects in the document.</p>"},{"location":"reference/#lintdb.core.Document.id","title":"id  <code>property</code>","text":"<pre><code>id\n</code></pre> <p>Unique ID of the document.</p>"},{"location":"reference/#lintdb.core.Duration","title":"Duration","text":"<pre><code>Duration(*args, **kwargs)\n</code></pre> <p>Duration type</p>"},{"location":"reference/#lintdb.core.FieldParameters","title":"FieldParameters","text":"<pre><code>FieldParameters()\n</code></pre> <p>Field parameters for configuration</p> <p>Default constructor</p>"},{"location":"reference/#lintdb.core.FieldParameters.analyzer","title":"analyzer  <code>property</code>","text":"<pre><code>analyzer\n</code></pre> <p>Analyzer type</p>"},{"location":"reference/#lintdb.core.FieldParameters.dimensions","title":"dimensions  <code>property</code>","text":"<pre><code>dimensions\n</code></pre> <p>Number of dimensions</p>"},{"location":"reference/#lintdb.core.FieldParameters.nbits","title":"nbits  <code>property</code>","text":"<pre><code>nbits\n</code></pre> <p>Number of bits</p>"},{"location":"reference/#lintdb.core.FieldParameters.num_centroids","title":"num_centroids  <code>property</code>","text":"<pre><code>num_centroids\n</code></pre> <p>Number of centroids</p>"},{"location":"reference/#lintdb.core.FieldParameters.num_iterations","title":"num_iterations  <code>property</code>","text":"<pre><code>num_iterations\n</code></pre> <p>Number of iterations</p>"},{"location":"reference/#lintdb.core.FieldParameters.num_subquantizers","title":"num_subquantizers  <code>property</code>","text":"<pre><code>num_subquantizers\n</code></pre> <p>Number of subquantizers</p>"},{"location":"reference/#lintdb.core.FieldParameters.quantization","title":"quantization  <code>property</code>","text":"<pre><code>quantization\n</code></pre> <p>Quantization type</p>"},{"location":"reference/#lintdb.core.FieldType","title":"FieldType","text":"<p>               Bases: <code>enum.Enum</code></p>"},{"location":"reference/#lintdb.core.FieldType.Colbert","title":"Colbert","text":"<pre><code>Colbert = FieldType.Colbert\n</code></pre> <p>Colbert field type</p>"},{"location":"reference/#lintdb.core.FieldType.Context","title":"Context","text":"<pre><code>Context = FieldType.Context\n</code></pre> <p>Context field type</p>"},{"location":"reference/#lintdb.core.FieldType.Indexed","title":"Indexed","text":"<pre><code>Indexed = FieldType.Indexed\n</code></pre> <p>Indexed field type</p>"},{"location":"reference/#lintdb.core.FieldType.Stored","title":"Stored","text":"<pre><code>Stored = FieldType.Stored\n</code></pre> <p>Stored field type</p>"},{"location":"reference/#lintdb.core.FieldValue","title":"FieldValue","text":"<pre><code>FieldValue()\n</code></pre> <p>FieldValue for storing different types of data.</p> <p>init(self, name: str, value: float) -&gt; None init(self, name: str, value: str) -&gt; None init(self, name: str, value: lintdb.core.DateTime) -&gt; None init(self, name: str, value: collections.abc.Sequence[float]) -&gt; None init(self, name: str, value: collections.abc.Sequence[float], num_tensors: int) -&gt; None init(self, name: str, value: collections.abc.Sequence[int], num_tensors: int) -&gt; None init(self, name: str, value: lintdb.core.ColBERTContextData, num_tensors: int) -&gt; None</p> <p>Overloaded function.</p> <ol> <li><code>__init__(self) -&gt; None</code></li> </ol> <p>Default constructor.</p> <ol> <li><code>__init__(self, name: str, value: int) -&gt; None</code></li> </ol> <p>Constructor with integer value.</p> <p>:param name: Field name. :param value: Integer value.</p> <ol> <li><code>__init__(self, name: str, value: float) -&gt; None</code></li> </ol> <p>Constructor with float value.</p> <p>:param name: Field name. :param value: Float value.</p> <ol> <li><code>__init__(self, name: str, value: str) -&gt; None</code></li> </ol> <p>Constructor with string value.</p> <p>:param name: Field name. :param value: String value.</p> <ol> <li><code>__init__(self, name: str, value: lintdb.core.DateTime) -&gt; None</code></li> </ol> <p>Constructor with DateTime value.</p> <p>:param name: Field name. :param value: DateTime value.</p> <ol> <li><code>__init__(self, name: str, value: collections.abc.Sequence[float]) -&gt; None</code></li> </ol> <p>Constructor with Tensor value.</p> <p>:param name: Field name. :param value: Tensor value.</p> <ol> <li><code>__init__(self, name: str, value: collections.abc.Sequence[float], num_tensors: int) -&gt; None</code></li> </ol> <p>Constructor with Tensor value and number of tensors.</p> <p>:param name: Field name. :param value: Tensor value. :param num_tensors: Number of tensors.</p> <ol> <li><code>__init__(self, name: str, value: collections.abc.Sequence[int], num_tensors: int) -&gt; None</code></li> </ol> <p>Constructor with QuantizedTensor value and number of tensors.</p> <p>:param name: Field name. :param value: QuantizedTensor value. :param num_tensors: Number of tensors.</p> <ol> <li><code>__init__(self, name: str, value: lintdb.core.ColBERTContextData, num_tensors: int) -&gt; None</code></li> </ol> <p>Constructor with ColBERTContextData value and number of tensors.</p> <p>:param name: Field name. :param value: ColBERTContextData value. :param num_tensors: Number of tensors.</p>"},{"location":"reference/#lintdb.core.FieldValue.data_type","title":"data_type  <code>property</code>","text":"<pre><code>data_type\n</code></pre> <p>Field data type.</p>"},{"location":"reference/#lintdb.core.FieldValue.name","title":"name  <code>property</code>","text":"<pre><code>name\n</code></pre> <p>Field name.</p>"},{"location":"reference/#lintdb.core.FieldValue.num_tensors","title":"num_tensors  <code>property</code>","text":"<pre><code>num_tensors\n</code></pre> <p>Number of tensors.</p>"},{"location":"reference/#lintdb.core.FieldValue.value","title":"value  <code>property</code>","text":"<pre><code>value\n</code></pre> <p>Field value.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer","title":"ICoarseQuantizer","text":"<pre><code>ICoarseQuantizer(*args, **kwargs)\n</code></pre> <p>Abstract ICoarseQuantizer class providing an interface for coarse quantization operations.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.add","title":"add  <code>method descriptor</code>","text":"<pre><code>add()\n</code></pre> <p>add(self, n: int, data: float) -&gt; None</p> <p>Add new data points to the coarse quantizer.</p> <p>:param n: Number of data points. :param data: Pointer to data points.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.assign","title":"assign  <code>method descriptor</code>","text":"<pre><code>assign()\n</code></pre> <p>assign(self, n: int, x: float, codes: int) -&gt; None</p> <p>Assign the nearest centroids to the given data points.</p> <p>:param n: Number of data points. :param x: Pointer to data. :param codes: Pointer to assigned codes.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.code_size","title":"code_size  <code>method descriptor</code>","text":"<pre><code>code_size()\n</code></pre> <p>code_size(self) -&gt; int</p> <p>Get the size of the code.</p> <p>:return: Size of the code.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.compute_residual","title":"compute_residual  <code>method descriptor</code>","text":"<pre><code>compute_residual()\n</code></pre> <p>compute_residual(self, vec: float, residual: float, centroid_id: int) -&gt; None</p> <p>Compute the residual vector for a given data point and centroid.</p> <p>:param vec: Pointer to data point. :param residual: Pointer to residual vector. :param centroid_id: Centroid ID.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.compute_residual_n","title":"compute_residual_n  <code>method descriptor</code>","text":"<pre><code>compute_residual_n()\n</code></pre> <p>compute_residual_n(self, n: int, vec: float, residual: float, centroid_ids: int) -&gt; None</p> <p>Compute the residual vectors for multiple data points and centroids.</p> <p>:param n: Number of data points. :param vec: Pointer to data points. :param residual: Pointer to residual vectors. :param centroid_ids: Pointer to centroid IDs.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.get_xb","title":"get_xb  <code>method descriptor</code>","text":"<pre><code>get_xb()\n</code></pre> <p>get_xb(self) -&gt; float</p> <p>Get the centroids.</p> <p>:return: Pointer to centroids.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.is_trained","title":"is_trained  <code>method descriptor</code>","text":"<pre><code>is_trained()\n</code></pre> <p>is_trained(self) -&gt; bool</p> <p>Check if the coarse quantizer is trained.</p> <p>:return: True if trained, False otherwise.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.num_centroids","title":"num_centroids  <code>method descriptor</code>","text":"<pre><code>num_centroids()\n</code></pre> <p>num_centroids(self) -&gt; int</p> <p>Get the number of centroids.</p> <p>:return: Number of centroids.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.reconstruct","title":"reconstruct  <code>method descriptor</code>","text":"<pre><code>reconstruct()\n</code></pre> <p>reconstruct(self, centroid_id: int, embedding: float) -&gt; None</p> <p>Reconstruct the embedding for a given centroid.</p> <p>:param centroid_id: Centroid ID. :param embedding: Pointer to reconstructed embedding.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.reset","title":"reset  <code>method descriptor</code>","text":"<pre><code>reset()\n</code></pre> <p>reset(self) -&gt; None</p> <p>Reset the coarse quantizer.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.sa_decode","title":"sa_decode  <code>method descriptor</code>","text":"<pre><code>sa_decode()\n</code></pre> <p>sa_decode(self, n: int, codes: int, x: float) -&gt; None</p> <p>Decode the given codes to data points.</p> <p>:param n: Number of data points. :param codes: Pointer to codes. :param x: Pointer to decoded data.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.save","title":"save  <code>method descriptor</code>","text":"<pre><code>save()\n</code></pre> <p>save(self, path: str) -&gt; None</p> <p>Save the coarse quantizer to the specified path.</p> <p>:param path: Path to save the quantizer.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.search","title":"search  <code>method descriptor</code>","text":"<pre><code>search()\n</code></pre> <p>search(self, num_query_tok: int, data: float, k_top_centroids: int, distances: float, coarse_idx: int) -&gt; None</p> <p>Search for the nearest centroids to the given data points.</p> <p>:param num_query_tok: Number of query tokens. :param data: Pointer to data points. :param k_top_centroids: Number of top centroids to search. :param distances: Pointer to distances to nearest centroids. :param coarse_idx: Pointer to coarse indices of nearest centroids.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.serialize","title":"serialize  <code>method descriptor</code>","text":"<pre><code>serialize()\n</code></pre> <p>serialize(self, filename: str) -&gt; None</p> <p>Serialize the coarse quantizer to a file.</p> <p>:param filename: File name to serialize to.</p>"},{"location":"reference/#lintdb.core.ICoarseQuantizer.train","title":"train  <code>method descriptor</code>","text":"<pre><code>train()\n</code></pre> <p>train(self, n: int, x: float, k: int, num_iter: int) -&gt; None</p> <p>Train the coarse quantizer with the given data.</p> <p>:param n: Number of data points. :param x: Pointer to data. :param k: Number of centroids. :param num_iter: Number of iterations.</p>"},{"location":"reference/#lintdb.core.IndexIVF","title":"IndexIVF","text":"<pre><code>IndexIVF()\n</code></pre> <p>IndexIVF is a multi-vector index with an inverted file structure.</p> <p>init(self, other: lintdb.core.IndexIVF, path: str) -&gt; None</p> <p>Overloaded function.</p> <ol> <li><code>__init__(self, path: str, read_only: bool = False) -&gt; None</code></li> </ol> <p>Load an existing index.</p> <p>:param path: The path to the index. :param read_only: Whether to open the index in read-only mode.</p> <ol> <li><code>__init__(self, path: str, schema: lintdb.core.Schema, config: lintdb.core.Configuration) -&gt; None</code></li> </ol> <p>Create a new index with the given path, schema, and configuration.</p> <p>:param path: The path to initialize the index. :param schema: The schema for the index. :param config: The configuration for the index.</p> <ol> <li><code>__init__(self, other: lintdb.core.IndexIVF, path: str) -&gt; None</code></li> </ol> <p>Create a copy of a trained index at the given path. The copy will always be writable.</p> <p>Throws an exception if the index isn't trained when this method is called.</p> <p>:param other: The other IndexIVF to copy. :param path: The path to initialize the new index.</p>"},{"location":"reference/#lintdb.core.IndexIVF.config","title":"config  <code>property</code>","text":"<pre><code>config\n</code></pre> <p>Configuration of the index.</p>"},{"location":"reference/#lintdb.core.IndexIVF.read_only","title":"read_only  <code>property</code>","text":"<pre><code>read_only\n</code></pre> <p>Flag indicating whether the index is read-only.</p>"},{"location":"reference/#lintdb.core.IndexIVF.add","title":"add  <code>method descriptor</code>","text":"<pre><code>add()\n</code></pre> <p>add(self, tenant: int, docs: collections.abc.Sequence[lintdb.core.Document]) -&gt; None</p> <p>Add a block of embeddings to the index.</p> <p>:param tenant: The tenant to assign the documents to. :param docs: A vector of documents to add.</p>"},{"location":"reference/#lintdb.core.IndexIVF.add_single","title":"add_single  <code>method descriptor</code>","text":"<pre><code>add_single()\n</code></pre> <p>add_single(self, tenant: int, doc: lintdb.core.Document) -&gt; None</p> <p>Add a single document to the index.</p> <p>:param tenant: The tenant to assign the document to. :param doc: The document to add.</p>"},{"location":"reference/#lintdb.core.IndexIVF.close","title":"close  <code>method descriptor</code>","text":"<pre><code>close()\n</code></pre> <p>close(self) -&gt; None</p> <p>Close the index, releasing any resources.</p>"},{"location":"reference/#lintdb.core.IndexIVF.merge","title":"merge  <code>method descriptor</code>","text":"<pre><code>merge()\n</code></pre> <p>merge(self, path: str) -&gt; None</p> <p>Merge the index with another index.</p> <p>This enables easier multiprocess building of indices but can have subtle issues if indices have different centroids.</p> <p>:param path: The path to the other index.</p>"},{"location":"reference/#lintdb.core.IndexIVF.remove","title":"remove  <code>method descriptor</code>","text":"<pre><code>remove()\n</code></pre> <p>remove(self, tenant: int, ids: collections.abc.Sequence[int]) -&gt; None</p> <p>Remove documents from the index by their IDs.</p> <p>:param tenant: The tenant the documents belong to. :param ids: The IDs of the documents to remove.</p>"},{"location":"reference/#lintdb.core.IndexIVF.save","title":"save  <code>method descriptor</code>","text":"<pre><code>save()\n</code></pre> <p>save(self) -&gt; None</p> <p>Save the current state of the index. Quantization and compression will be saved within the Index's path.</p>"},{"location":"reference/#lintdb.core.IndexIVF.search","title":"search  <code>method descriptor</code>","text":"<pre><code>search()\n</code></pre> <p>search(self, tenant: int, query: lintdb.core.Query, k: int, opts: dict = {}) -&gt; list[lintdb.core.SearchResult]</p> <p>Find the nearest neighbors for a vector block.</p> <p>:param tenant: The tenant the document belongs to. :param query: The query to search with. :param k: The number of top results to return. :param opts: Search options to use during searching.</p>"},{"location":"reference/#lintdb.core.IndexIVF.set_coarse_quantizer","title":"set_coarse_quantizer  <code>method descriptor</code>","text":"<pre><code>set_coarse_quantizer()\n</code></pre> <p>set_coarse_quantizer(self, field: str, quantizer: lintdb.core.ICoarseQuantizer) -&gt; None</p> <p>Set the coarse quantizer for a field.</p> <p>:param field: The field to set the coarse quantizer for. :param quantizer: The coarse quantizer to set.</p>"},{"location":"reference/#lintdb.core.IndexIVF.set_quantizer","title":"set_quantizer  <code>method descriptor</code>","text":"<pre><code>set_quantizer()\n</code></pre> <p>set_quantizer(self, field: str, quantizer: lintdb.core.Quantizer) -&gt; None</p> <p>Set the quantizer for a field.</p> <p>:param field: The field to set the quantizer for. :param quantizer: The quantizer to set.</p>"},{"location":"reference/#lintdb.core.IndexIVF.train","title":"train  <code>method descriptor</code>","text":"<pre><code>train()\n</code></pre> <p>train(self, docs: collections.abc.Sequence[lintdb.core.Document]) -&gt; None</p> <p>Train the index with the given documents to learn quantization and compression parameters.</p> <p>:param docs: The documents to use for training.</p>"},{"location":"reference/#lintdb.core.IndexIVF.update","title":"update  <code>method descriptor</code>","text":"<pre><code>update()\n</code></pre> <p>update(self, tenant: int, docs: collections.abc.Sequence[lintdb.core.Document]) -&gt; None</p> <p>Update documents in the index. This is a convenience function for remove and add.</p> <p>:param tenant: The tenant the documents belong to. :param docs: The documents to update.</p>"},{"location":"reference/#lintdb.core.Quantizer","title":"Quantizer","text":"<pre><code>Quantizer(*args, **kwargs)\n</code></pre> <p>Abstract Quantizer class providing an interface for quantization operations.</p>"},{"location":"reference/#lintdb.core.Quantizer.code_size","title":"code_size  <code>method descriptor</code>","text":"<pre><code>code_size()\n</code></pre> <p>code_size(self) -&gt; int</p> <p>Get the size of the code.</p> <p>:return: Size of the code.</p>"},{"location":"reference/#lintdb.core.Quantizer.get_nbits","title":"get_nbits  <code>method descriptor</code>","text":"<pre><code>get_nbits()\n</code></pre> <p>get_nbits(self) -&gt; int</p> <p>Get the number of bits.</p> <p>:return: Number of bits.</p>"},{"location":"reference/#lintdb.core.Quantizer.get_type","title":"get_type  <code>method descriptor</code>","text":"<pre><code>get_type()\n</code></pre> <p>get_type(self) -&gt; lintdb.core.QuantizerType</p> <p>Get the type of quantizer.</p> <p>:return: Quantizer type.</p>"},{"location":"reference/#lintdb.core.Quantizer.sa_decode","title":"sa_decode  <code>method descriptor</code>","text":"<pre><code>sa_decode()\n</code></pre> <p>sa_decode(self, n: int, codes: int, x: float) -&gt; None</p> <p>Decode the given data using the quantizer.</p> <p>:param n: Number of data points. :param codes: Pointer to encoded data. :param x: Pointer to decoded data.</p>"},{"location":"reference/#lintdb.core.Quantizer.sa_encode","title":"sa_encode  <code>method descriptor</code>","text":"<pre><code>sa_encode()\n</code></pre> <p>sa_encode(self, n: int, x: float, codes: int) -&gt; None</p> <p>Encode the given data using the quantizer.</p> <p>:param n: Number of data points. :param x: Pointer to data. :param codes: Pointer to encoded data.</p>"},{"location":"reference/#lintdb.core.Quantizer.save","title":"save  <code>method descriptor</code>","text":"<pre><code>save()\n</code></pre> <p>save(self, path: str) -&gt; None</p> <p>Save the quantizer to the specified path.</p> <p>:param path: Path to save the quantizer.</p>"},{"location":"reference/#lintdb.core.Quantizer.train","title":"train  <code>method descriptor</code>","text":"<pre><code>train()\n</code></pre> <p>train(self, n: int, x: float, dim: int) -&gt; None</p> <p>Train the quantizer with the given data.</p> <p>:param n: Number of data points. :param x: Pointer to data. :param dim: Dimension size.</p>"},{"location":"reference/#lintdb.core.QuantizerType","title":"QuantizerType","text":"<p>               Bases: <code>enum.Enum</code></p> <p>Enumeration of quantizer types.</p>"},{"location":"reference/#lintdb.core.QuantizerType.BINARIZER","title":"BINARIZER","text":"<pre><code>BINARIZER = QuantizerType.BINARIZER\n</code></pre> <p>Binarizer quantizer.</p>"},{"location":"reference/#lintdb.core.QuantizerType.NONE","title":"NONE","text":"<pre><code>NONE = QuantizerType.NONE\n</code></pre> <p>No quantizer.</p>"},{"location":"reference/#lintdb.core.QuantizerType.PRODUCT_ENCODER","title":"PRODUCT_ENCODER","text":"<pre><code>PRODUCT_ENCODER = QuantizerType.PRODUCT_ENCODER\n</code></pre> <p>Product encoder quantizer.</p>"},{"location":"reference/#lintdb.core.QuantizerType.UNKNOWN","title":"UNKNOWN","text":"<pre><code>UNKNOWN = QuantizerType.UNKNOWN\n</code></pre> <p>Unknown quantizer type.</p>"},{"location":"reference/#lintdb.core.Query","title":"Query","text":"<pre><code>Query()\n</code></pre> <p>Query object containing a root query node.</p> <p>Constructor with a unique pointer to the root query node.</p> <p>:param root: Unique pointer to the root query node.</p>"},{"location":"reference/#lintdb.core.QueryNodeType","title":"QueryNodeType","text":"<p>               Bases: <code>enum.Enum</code></p> <p>Types of query nodes.</p>"},{"location":"reference/#lintdb.core.QueryNodeType.AND","title":"AND","text":"<pre><code>AND = QueryNodeType.AND\n</code></pre> <p>AND query node.</p>"},{"location":"reference/#lintdb.core.QueryNodeType.TERM","title":"TERM","text":"<pre><code>TERM = QueryNodeType.TERM\n</code></pre> <p>Term query node.</p>"},{"location":"reference/#lintdb.core.QueryNodeType.VECTOR","title":"VECTOR","text":"<pre><code>VECTOR = QueryNodeType.VECTOR\n</code></pre> <p>Vector query node.</p>"},{"location":"reference/#lintdb.core.Schema","title":"Schema","text":"<pre><code>Schema()\n</code></pre> <p>Schema configuration</p> <p>Overloaded function.</p> <ol> <li><code>__init__(self) -&gt; None</code></li> </ol> <p>Default constructor</p> <ol> <li><code>__init__(self, arg: collections.abc.Sequence[lintdb.core.__Field], /) -&gt; None</code></li> </ol> <p>Constructor with fields</p>"},{"location":"reference/#lintdb.core.Schema.fields","title":"fields  <code>property</code>","text":"<pre><code>fields\n</code></pre> <p>Fields in the schema</p>"},{"location":"reference/#lintdb.core.Schema.add_field","title":"add_field  <code>method descriptor</code>","text":"<pre><code>add_field()\n</code></pre> <p>add_field(self, arg: lintdb.core.__Field, /) -&gt; None</p> <p>Add a field to the schema</p>"},{"location":"reference/#lintdb.core.Schema.fromJson","title":"fromJson","text":"<pre><code>fromJson()\n</code></pre> <p>fromJson(arg: Json::Value, /) -&gt; lintdb.core.Schema</p> <p>Create schema from JSON</p>"},{"location":"reference/#lintdb.core.Schema.toJson","title":"toJson  <code>method descriptor</code>","text":"<pre><code>toJson()\n</code></pre> <p>toJson(self) -&gt; Json::Value</p> <p>Convert schema to JSON</p>"},{"location":"reference/#lintdb.core.SearchOptions","title":"SearchOptions","text":"<pre><code>SearchOptions()\n</code></pre> <p>SearchOptions enables custom searching behavior.</p> <p>These options expose ways to tradeoff recall and latency at different levels of retrieval. To search more centroids: - Decrease <code>centroid_score_threshold</code> and increase <code>k_top_centroids</code>. - Increase <code>n_probe</code> in search(). To decrease latency: - Increase <code>centroid_score_threshold</code> and decrease <code>k_top_centroids</code>. - Decrease <code>n_probe</code> in search().</p> <p>Default constructor</p>"},{"location":"reference/#lintdb.core.SearchOptions.centroid_score_threshold","title":"centroid_score_threshold  <code>property</code>","text":"<pre><code>centroid_score_threshold\n</code></pre> <p>The threshold for centroid scores. Lower values mean more centroids are considered.</p>"},{"location":"reference/#lintdb.core.SearchOptions.colbert_field","title":"colbert_field  <code>property</code>","text":"<pre><code>colbert_field\n</code></pre> <p>The field to use for ColBERT (Contextualized Late Interaction over BERT).</p>"},{"location":"reference/#lintdb.core.SearchOptions.expected_id","title":"expected_id  <code>property</code>","text":"<pre><code>expected_id\n</code></pre> <p>Expects a document ID in the return result. Prints additional information during execution. Useful for debugging.</p>"},{"location":"reference/#lintdb.core.SearchOptions.k_top_centroids","title":"k_top_centroids  <code>property</code>","text":"<pre><code>k_top_centroids\n</code></pre> <p>The number of top centroids to consider per token. Higher values mean more centroids are considered.</p>"},{"location":"reference/#lintdb.core.SearchOptions.n_probe","title":"n_probe  <code>property</code>","text":"<pre><code>n_probe\n</code></pre> <p>The number of centroids to search overall. Higher values mean more centroids are searched.</p>"},{"location":"reference/#lintdb.core.SearchOptions.nearest_tokens_to_fetch","title":"nearest_tokens_to_fetch  <code>property</code>","text":"<pre><code>nearest_tokens_to_fetch\n</code></pre> <p>The number of nearest tokens to fetch in XTR. Higher values mean more tokens are fetched.</p>"},{"location":"reference/#lintdb.core.SearchOptions.num_second_pass","title":"num_second_pass  <code>property</code>","text":"<pre><code>num_second_pass\n</code></pre> <p>The number of second pass candidates to consider. Higher values mean more candidates are considered.</p>"},{"location":"reference/#lintdb.core.SearchResult","title":"SearchResult","text":"<pre><code>SearchResult()\n</code></pre> <p>Search result</p> <p>Default constructor</p>"},{"location":"reference/#lintdb.core.SearchResult.id","title":"id  <code>property</code>","text":"<pre><code>id\n</code></pre> <p>Document ID</p>"},{"location":"reference/#lintdb.core.SearchResult.metadata","title":"metadata  <code>property</code>","text":"<pre><code>metadata\n</code></pre> <p>Metadata for the document</p>"},{"location":"reference/#lintdb.core.SearchResult.score","title":"score  <code>property</code>","text":"<pre><code>score\n</code></pre> <p>Final score</p>"},{"location":"reference/#lintdb.core.SupportedTypes","title":"SupportedTypes","text":"<pre><code>SupportedTypes(*args, **kwargs)\n</code></pre> <p>Supported data types</p>"},{"location":"reference/#lintdb.core.Version","title":"Version","text":"<pre><code>Version()\n</code></pre> <p>Version class representing LintDB's version with major, minor, revision, and build numbers.</p> <p>Overloaded function.</p> <ol> <li><code>__init__(self) -&gt; None</code></li> </ol> <p>Default constructor.</p> <ol> <li><code>__init__(self, versionStr: str) -&gt; None</code></li> </ol> <p>Constructor with version string.</p> <p>:param versionStr: Version string in the format 'major.minor.revision'.</p>"},{"location":"reference/#lintdb.core.Version.build","title":"build  <code>property</code>","text":"<pre><code>build\n</code></pre> <p>Build number.</p>"},{"location":"reference/#lintdb.core.Version.major","title":"major  <code>property</code>","text":"<pre><code>major\n</code></pre> <p>Major version number.</p>"},{"location":"reference/#lintdb.core.Version.metadata_enabled","title":"metadata_enabled  <code>property</code>","text":"<pre><code>metadata_enabled\n</code></pre> <p>Flag indicating if metadata is enabled.</p>"},{"location":"reference/#lintdb.core.Version.minor","title":"minor  <code>property</code>","text":"<pre><code>minor\n</code></pre> <p>Minor version number.</p>"},{"location":"reference/#lintdb.core.Version.revision","title":"revision  <code>property</code>","text":"<pre><code>revision\n</code></pre> <p>Revision number.</p>"},{"location":"reference/#lintdb.core.AndQueryNode","title":"AndQueryNode","text":"<pre><code>AndQueryNode()\n</code></pre> <p>AndQueryNode(its: collections.abc.Sequence[lintdb.core.__QueryNode]) -&gt; lintdb.core.__QueryNode</p>"},{"location":"reference/#lintdb.core.Binarizer","title":"Binarizer","text":"<pre><code>Binarizer()\n</code></pre> <p>Binarizer(arg0: collections.abc.Sequence[float], arg1: collections.abc.Sequence[float], arg2: float, arg3: int, arg4: int, /) -&gt; lintdb.core._Binarizer</p> <p>Create a Binarizer object</p>"},{"location":"reference/#lintdb.core.ColbertField","title":"ColbertField","text":"<pre><code>ColbertField()\n</code></pre> <p>ColbertField(arg0: str, arg1: lintdb.core.DataType, arg2: dict, /) -&gt; lintdb.core.__ColbertField</p> <p>Create a ColbertField object</p>"},{"location":"reference/#lintdb.core.ContextField","title":"ContextField","text":"<pre><code>ContextField()\n</code></pre> <p>ContextField(arg0: str, arg1: lintdb.core.DataType, arg2: dict, /) -&gt; lintdb.core.__ContextField</p> <p>Create a ContextField object</p>"},{"location":"reference/#lintdb.core.DateFieldValue","title":"DateFieldValue","text":"<pre><code>DateFieldValue()\n</code></pre> <p>DateFieldValue(arg0: str, arg1: object, /) -&gt; lintdb.core.FieldValue</p> <p>Create FieldValue from DateTime</p>"},{"location":"reference/#lintdb.core.FaissCoarseQuantizer","title":"FaissCoarseQuantizer","text":"<pre><code>FaissCoarseQuantizer()\n</code></pre> <p>FaissCoarseQuantizer(centroids: ndarray[dtype=float32, device='cpu']) -&gt; lintdb.core._FaissCoarseQuantizer</p>"},{"location":"reference/#lintdb.core.Field","title":"Field","text":"<pre><code>Field()\n</code></pre> <p>Field(arg0: str, arg1: lintdb.core.DataType, arg2: collections.abc.Sequence[lintdb.core.FieldType], arg3: dict, /) -&gt; lintdb.core.__Field</p> <p>Create a Field object</p>"},{"location":"reference/#lintdb.core.FloatFieldValue","title":"FloatFieldValue","text":"<pre><code>FloatFieldValue()\n</code></pre> <p>FloatFieldValue(arg0: str, arg1: float, /) -&gt; lintdb.core.FieldValue</p> <p>Create FieldValue from float</p>"},{"location":"reference/#lintdb.core.IndexedField","title":"IndexedField","text":"<pre><code>IndexedField()\n</code></pre> <p>IndexedField(arg0: str, arg1: lintdb.core.DataType, arg2: dict, /) -&gt; lintdb.core.__IndexedField</p> <p>Create an IndexedField object</p>"},{"location":"reference/#lintdb.core.IntFieldValue","title":"IntFieldValue","text":"<pre><code>IntFieldValue()\n</code></pre> <p>IntFieldValue(arg0: str, arg1: int, /) -&gt; lintdb.core.FieldValue</p> <p>Create FieldValue from integer</p>"},{"location":"reference/#lintdb.core.QuantizedTensorFieldValue","title":"QuantizedTensorFieldValue","text":"<pre><code>QuantizedTensorFieldValue()\n</code></pre> <p>QuantizedTensorFieldValue(arg0: str, arg1: ndarray[dtype=uint8, shape=(, ), device='cpu'], /) -&gt; lintdb.core.FieldValue</p> <p>Create FieldValue from QuantizedTensor</p>"},{"location":"reference/#lintdb.core.StoredField","title":"StoredField","text":"<pre><code>StoredField()\n</code></pre> <p>StoredField(arg0: str, arg1: lintdb.core.DataType, arg2: dict, /) -&gt; lintdb.core.__StoredField</p> <p>Create a StoredField object</p>"},{"location":"reference/#lintdb.core.TensorFieldValue","title":"TensorFieldValue","text":"<pre><code>TensorFieldValue()\n</code></pre> <p>TensorFieldValue(arg0: str, arg1: ndarray[dtype=float32, shape=(, ), device='cpu'], /) -&gt; lintdb.core.FieldValue</p> <p>Create FieldValue from Tensor</p>"},{"location":"reference/#lintdb.core.TermQueryNode","title":"TermQueryNode","text":"<pre><code>TermQueryNode()\n</code></pre> <p>TermQueryNode(value: lintdb.core.FieldValue) -&gt; lintdb.core.__QueryNode</p>"},{"location":"reference/#lintdb.core.TextFieldValue","title":"TextFieldValue","text":"<pre><code>TextFieldValue()\n</code></pre> <p>TextFieldValue(arg0: str, arg1: str, /) -&gt; lintdb.core.FieldValue</p> <p>Create FieldValue from string</p>"},{"location":"reference/#lintdb.core.VectorQueryNode","title":"VectorQueryNode","text":"<pre><code>VectorQueryNode()\n</code></pre> <p>VectorQueryNode(value: lintdb.core.FieldValue) -&gt; lintdb.core.__QueryNode</p>"}]}